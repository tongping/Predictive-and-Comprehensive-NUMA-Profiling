\section{Introduction}
\label{sec:intro}

\todo{he reviewers are mainly concerned with the following issues: (1) The novelty aspects of NumaPerf need to be clarified, (2) the contribution seems narrow and some of the contributions seem overstated , (3) the writing needs some work. }

\todo{Fixing > 1.6x speed-up --> 60\% improvement}

The Non-Uniform Memory Access (NUMA) is the de facto design to address the scalability issue with an increased number of hardware cores. Compared to the Uniform Memory Access (UMA) architecture, the NUMA architecture avoids the bottleneck of one memory controller by allowing each node/processor to concurrently access its own memory controller. However, the NUMA architecture imposes multiple system challenges for writing efficient parallel applications, such as remote accesses, cache contention, interconnect congestion, and node imbalance~\cite{Blagodurov:2011:CNC:2002181.2002182}. User programs could easily suffer from significant performance degradation, necessitating the development of profiling tools to identify NUMA-related performance issues. 

General-purpose profilers, such as \texttt{gprof}~\cite{DBLP:conf/sigplan/GrahamKM82}, \texttt{perf}~\cite{perf}, or \texttt{Coz}~\cite{Coz}, are not suitable for identifying NUMA-related performance issues~\cite{XuNuma,valat:2018:numaprof} because they are agnostic to the architecture difference. 
%Existing NUMA-related profiling tools can be largely classified into three types. One 
To detect NUMA-related issues, one type of tools
simulates cache activities and page affinity based on the collected memory traces~\cite{NUMAGrind, MACPO}. However, they may introduce significant performance slowdown, preventing their uses even in development phases. Another type of profiler employs coarse-grained hardware sampling to identify performance issues in the deployment environment~\cite{Intel:VTune, Memphis, Lachaize:2012:MMP:2342821.2342826, XuNuma, NumaMMA, 7847070}, while the third type builds on fine-grained instrumentation that could detect more performance issues but with a higher overhead~\cite{diener2015characterizing, valat:2018:numaprof}. 
%Among them, profiling-based tools may miss some performance opportunities, and provide misleading information for fixes.  
%Due to this fact, fine-grained tools are more suitable for the development phase, which aims to detect as many performance issues as possible before the release of software. 

%\todo{Do existing work differentiate false sharing and true sharing? This is important since false sharing and true sharing will require different fixes, and most true-sharing can be very difficult to fix} 

However, the latter two types of tools share the following \textbf{common issues}. \textit{First, they mainly focus on one type of performance issues (i.e., remote accesses), while omitting other types of issues that may have a larger performance impact}. 
%thread migration that could incur remote accesses, and omit load imbalance that may have a larger performance impact. As a result, they , as shown in our evaluation. 
\textit{Second, they have limited portability that can only identify remote accesses on the current NUMA hardware}. The major reason is that they rely on the physical node information to detect remote accesses, where the physical page a thread accesses is located in a node different from the node of the current thread. However, 
the relationship between threads/pages with physical nodes can be varied when an application is running on different hardware with different topology, or even on the same hardware at another time. That is, existing tools may miss some remote accesses caused by the hardware and the schedule. \textit{Third, existing tools could not provide sufficient guidelines to fix these issues}. Users have to spend significant effort to figure out the corresponding fix strategies manually. 


This paper proposes a novel tool---\NP{}---that overcomes these issues. \NP{} is designed as an automatic tool that does not require human annotation or the change of application. It also does not require new hardware or a customized operating system. \NP{} aims to detect NUMA-related issues in development phases when applications are fed with representative inputs. In this way, there is no need to pay additional and unnecessary runtime overhead in deployment phases. We further describe \NP{}'s distinctive goals and designs as follows. 

First, \NP{} aims to detect more types of NUMA performance issues, while existing NUMA profilers  only focus on remote accesses. The first type is load imbalance among threads, which may lead to memory controller congestion and interconnect congestion. The second type is cross-node migration, which may turn all local accesses of a migrated thread into remote accesses. Based on our evaluation, cross-node migration may lead to $4.2\times$ performance degradation for \texttt{fluidanimate}. However, some applications may not have such issues, which requires the assistance of profiling tools.  

Second, it proposes a set of architecture-independent and scheduling-independent mechanisms that could predicatively detect the above-mentioned issues on any NUMA architecture, even the profiling is performed on a non-NUMA machine. \NP{}'s detection of remote accesses is based on a \textbf{key observation}:  memory sharing pattern of threads is an invariant determined by the program logic, but the relationship between threads/pages and physical nodes is architecture and scheduling dependent. Therefore, \textit{\NP{} focuses on identifying memory sharing pattern between threads, instead of the specific node relationship of threads and pages}, since a thread/page can be scheduled/allocated to/from a different node in a different execution. This mechanism not only simplifies the detection problem (without the need to track the node information) but also generalizes to different hardware architectures.  \NP{} relies on the relationship of memory accesses from each thread that is not affected by the scheduling, instead of the specific binding of threads (due to the scheduling).  \textit{\NP{} also proposes an architecture-independent mechanism to measure load imbalance}: when different types of threads have a different number of total memory accesses but with the same number of threads, then this application has a load imbalance issue. \textit{\NP{} further proposes a method to predict the probability of thread migrations.} \NP{} computes a migration score based on the contending number of synchronizations, and the number of condition and barrier waits. Overall, \NP{} predicts a set of NUMA performance issues without the requirement of testing on a NUMA machine, where its basic ideas are further discussed in Section~\ref{sec:idea}.   

Last but not least, \NP{} aims to provide more helpful information to fix NUMA performance issues. It proposes a set of metrics to measure the seriousness of different performance issues, preventing programmers from spending unnecessary efforts on insignificant issues. Its report could guide users for a better fix. For load imbalance issues, \NP{} suggests a thread assignment that could achieve much better performance than  existing work~\cite{SyncPerf}. For remote accesses, there exist multiple fix strategies with different levels of improvement. Currently, programmers have to figure out a good strategy by themselves. In contrast, \NP{} supplies more information to assist fixes. It separates cache false sharing issues from true sharing and page sharing so that users can use the padding to achieve better performance. It further reports whether the data can be duplicated or not by confirming the temporal relationship of memory reads/writes. It also reports threads accessing each page, which helps users to determine a better fix strategy.  
%whether a block-wise interleave with the thread binding will have a better performance improvement. 


We performed extensive experiments to verify the effectiveness of \NP{} with widely-used parallel applications (i.e., PARSEC~\cite{parsec}) and HPC applications (e.g., AMG2006~\cite{AMG2006}, lulesh~\cite{LULESH}, and UMT2013~\cite{UMT2013}). Based on our evaluation, \NP{} detects many more performance issues than the combination of all existing NUMA profilers, including both fine-grained and coarse-grained tools. After fixing such issues, most applications achieve significant performance speedup, where one application  achieves $5.94\times$ speedup.  \NP{}'s helpfulness on fixing performance issues is also exemplified by multiple case studies. Overall, \NP{} imposes less than $6\times$ performance overhead, which is orders of magnitude faster than the previous state-of-the-art in the fine-grained analysis. The experiments also confirm that \NP{}'s detection is architecture-independent and schedule-independent, which is able to identify most performance issues when running on a non-NUMA machine. 
%We further evaluates \NP{}'s performance and memory overhead. \NP{} introduces around $X\times$ performance overhead and 

Overall, \NP{} makes the following contributions. 

\begin{itemize}
    \item \NP{} proposes new architecture-independent and scheduling-independent methods that could predicatively detect NUMA-related performance issues, even without the requirement to evaluate on a NUMA architecture. 
    
    \item  \NP{} proposes a new mechanism to profile load imbalance issues based on the number of memory accesses, which provides a better prediction on the thread assignment.  
    
    \item \NP{} detects some omitted NUMA performance issues by existing tools, such as load imbalance, and thread migrations. 
    
    \item \NP{} designs a set of new metrics to measure the seriousness of performance issues and provides helpful information to assist their fixes.
    
     \item We have performed extensive evaluations to confirm \NP{}'s effectiveness and overhead.  
    
\end{itemize}


\subsection*{Outline}

The remainder of this paper is organized as follows. Section~\ref{sec:overview} introduces the background of NUMA architecture and the basic ideas of \NP{}. Then Section~\ref{sec:implementation} presents the detailed implementation and Section~\ref{sec:evaluation} shows experimental results. After that, Section~\ref{sec:discussion} explains the limitation and  Section~\ref{sec:related} discusses related work in this field. In the end, Section~\ref{sec:conclusion} concludes this paper.


 





