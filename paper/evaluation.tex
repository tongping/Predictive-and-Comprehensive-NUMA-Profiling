\section{Experimental Evaluation}
\label{sec:evaluation}

\todo{Can we differentiate the reason of remote accesses. First, we should differentiate false and true sharing. For true sharing, migratory (producer-consumer), simultaneously-shared, or read-mostly. }
\subsection{Effectiveness}
We will evaluate this work against two existing work:

%https://github.com/memtt/numaprof
%

\todo{We should detect more issues in real applications, such as Apache and MySQL and MemCached} 

\input{detectedIssuesTable}

\subsection{Performance Overhead}

\subsection{Memory Overhead}

\subsection{Sensitive To Inputs}
We further confirms that most performance issues can be detected with different inputs or commands. 

We may try Apache and MySQL to check whether the detected issues are changed with different inputs or different commands. 

Then we may reach a conclusion that there is no need to detect them during the deploy environment. 
