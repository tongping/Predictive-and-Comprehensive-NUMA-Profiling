\section{Experimental Evaluation}
\label{sec:evaluation}

\todo{Can we differentiate the reason of remote accesses. First, we should differentiate false and true sharing. For true sharing, we should at least differentiate read-mostly and others, since read-mostly are easier to achieve performance speedup. }
\subsection{Effectiveness}
We will evaluate this work against two existing work:

%https://github.com/memtt/numaprof
%

\todo{We should detect more issues in real applications, such as Apache and MySQL and MemCached} 

\input{detectedIssuesTable}

\subsection{Case Studies}
\label{sec:casestudies}

\subsubsection{Fixing Excessive Number of Remote Accesses}

\subsubsection{Fixing Thread Migration} 

\subsubsection{Fixing Load Imbalance}
\subsection{Performance Overhead}

\subsection{Memory Overhead}

\subsection{Sensitive To Inputs}
We further confirms that most performance issues can be detected with different inputs or commands. 

We may try Apache and MySQL to check whether the detected issues are changed with different inputs or different commands. 

Then we may reach a conclusion that there is no need to detect them during the deploy environment. 
